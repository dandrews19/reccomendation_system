# Yelp Recommendation System

## Overview
This project aims to develop a recommendation system using Yelp's dataset, focusing on providing personalized business recommendations to users. It leverages Apache Spark for distributed data processing, XGBoost for model-based recommendations, and collaborative filtering techniques to predict user ratings for businesses. The system utilizes various features from Yelp's rich datasets, including user and business attributes, to enhance recommendation accuracy.

## Installation

### Prerequisites
- Python 3.6+
- Apache Spark 3.0+
- Java 8 or 11 (required by Apache Spark)
- Hadoop 2.7+ (for HDFS support)

### Libraries
- pyspark
- xgboost
- optuna
- pandas
- numpy
- scikit-learn

### Setup
1. **Install Python Dependencies**: Install the required Python libraries using pip:
```
pip install pyspark xgboost optuna pandas numpy scikit-learn
```

2. **Apache Spark Setup**: Ensure that Apache Spark is installed and properly configured on your system. Refer to the [official Spark documentation](https://spark.apache.org/docs/latest/) for installation instructions.

3. **Environment Variables**: Set the `PYSPARK_PYTHON` environment variable to point to your Python executable, which is required for PySpark:
```
export PYSPARK_PYTHON=python3
```


## Model Training

To train the recommendation model, you simply need to run the `train_model.py` script. This script trains the model using the data prepared in the `prep_data_for_model.py` process and saves the trained model for future recommendation predictions.

### Steps for Model Training
1. **Prepare Your Dataset**: Ensure your Yelp dataset is placed in a known directory. This dataset should include `yelp_train.csv`, `yelp_val.csv`, `business.json`, and `user.json` files.

2. **Run the Training Script**: Execute the following command in your terminal, replacing `/path/to/data` with the actual path to your dataset:
```
spark-submit train_model.py /path/to/data
```

This will initiate the training process using the default hyperparameter settings defined within the script.

### Customizing Hyperparameters
The `train_model.py` script includes suggestions for hyperparameters that can be adjusted to potentially improve model performance. To customize the hyperparameter suggestions, open the `train_model.py` script in a text editor and modify the hyperparameter values within the `param` dictionary.

After adjusting the hyperparameters to your liking, save the changes and rerun the training script as described above to train the model with your new settings.

### Output
Upon successful training, the model will be saved as a `.pickle` file in the specified output directory. This model can then be used for making predictions in the recommendation system.

## Usage

### Running the Recommendation System
To run the recommendation system, ensure you have a pre-trained model available. The system can then generate recommendations based on the input data without the need for on-the-fly training. Follow these steps:

1. **Ensure Model Availability**: Confirm that the `final_xgb_model.pickle` file, generated by the model training process, is located in the `models` directory.

2. **Prepare Your Data**: Place your Yelp dataset (`yelp_train.csv`, `yelp_val.csv`, `business.json`, and `user.json`) in a directory accessible by Spark. The data should already be processed and ready for use by the recommendation system.

3. **Run the Recommendation System**:
- For collaborative filtering recommendations, execute:
  ```
  spark-submit collaborative_filtering.py /path/to/data
  ```
- For model-based recommendations using the pre-trained XGBoost model, ensure your environment is set up correctly (refer to the Installation section), and then execute the script that loads the model and performs the prediction.

### Note
This README assumes that the model training and hyperparameter tuning have already been completed. If this is not the case, refer to the **Model Training and Evaluation** and **Hyperparameter Tuning** sections for instructions on these processes.
